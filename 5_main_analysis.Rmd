---
title: 'A randomised trial to estimate the effect of funding on research productivity: Main analysis'
author: "Adrian Barnett"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  word_document:
    toc: true
    toc_depth: 1
    reference_docx: rmarkdown-styles-reference.docx
---

```{r setup, include=FALSE}
# using formatting in Word document (see above)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE, error=FALSE, comment='', dpi=400)
options(width=1000) # Wide pages
options(scipen=999) # avoid scientific presentation
source('99__functions.R')
library(dplyr)
library(tidyr)
library(stringr)
library(janitor) # for tables with column totals
library(flextable)
library(survival)
library(broom)
library(mitools) # for imputation
# Bayes packages:
library(nimble)
library(ggmcmc)
library(coda)
# plotting packages:
library(survminer)
library(gridExtra)
library(ggplot2)
g.theme = theme_bw() + theme(panel.grid.minor = element_blank())

# get the analysis-read data sets on funding and papers; with treatment variable, baseline counts and denominators
source('4_get_data.R')

# big switch that impacts all results (rename word doc)
only_consent = FALSE

## paper data, annual
analysis_ready = add_treatment_censored(in_random = researchers, 
                                        only_consent = only_consent,
                                        monthly = FALSE, 
                                        check_plot = FALSE,
                                        in_biblio = paper_counts)
## paper data, monthly - no longer used
#analysis_ready_monthly = add_treatment_censored(in_random = researchers, 
#                                                only_consent = only_consent,
#                                                in_biblio = paper_counts_monthly,
#                                                monthly = TRUE)
# quick fix for duplicated months/years (checked that all months and years are the same)
#analysis_ready_monthly = dplyr::select(analysis_ready_monthly, -month.x, -year.x, -year.y) %>%
#  rename('month' = 'month.y')
## citation data, annual 
analysis_ready_citations = add_treatment_censored(in_random = researchers, 
                                                only_consent = only_consent,
                                                in_biblio = citations,
                                                citations = TRUE,
                                                monthly = FALSE)
# quick fix for one person (#73) with missing data
f = season::yrfraction(scopus_date_citations)
analysis_ready_citations = mutate(analysis_ready_citations, 
  denom_scopus = ifelse(is.na(scopus)==TRUE, f, denom_scopus),
  scopus = ifelse(is.na(scopus)==TRUE, 0, scopus), 
  b_scopus = ifelse(is.na(b_scopus), 0, b_scopus))
## citation data, per paper 
analysis_ready_citations_per_paper = add_treatment_censored(in_random = researchers, 
                                                only_consent = only_consent,
                                                in_biblio = citations_per_paper,
                                                citations = TRUE,
                                                baseline_stat = 'last',
                                                monthly = FALSE)
# quick fix for one person (#73) with missing data
analysis_ready_citations_per_paper = mutate(analysis_ready_citations_per_paper, 
  denom_scopus = 1, # no need for offset as fewer papers cancel fewer citations
  scopus = ifelse(is.na(scopus)==TRUE, 0, scopus), 
  b_scopus = ifelse(is.na(b_scopus), 0, b_scopus))
## altmetric data, average per paper
analysis_ready_altmetric = add_treatment_censored(in_random = researchers, 
                                        only_consent = only_consent,
                                        is_altmetric = TRUE,
                                        monthly = FALSE, 
                                        baseline_stat = 'mean', 
                                        in_biblio = altmetric_average)
# quick fix for small amount of missing
analysis_ready_altmetric = mutate(analysis_ready_altmetric, 
  denom_altmetric = 1, # no need for offset as fewer papers cancel fewer citations
  altmetric = ifelse(is.na(altmetric )==TRUE, 0, altmetric), 
  b_altmetric = ifelse(is.na(b_altmetric), 0, b_altmetric))
## employment
analysis_ready_employment = add_treatment_employment(in_random = researchers, 
                            only_consent = only_consent)

### impute baseline counts for all three databases
# data created by '99_impute_bibliographic_only_baseline.R'
load('data/5_imputed.RData') # contains analysis_ready_imputed as a list
if(only_consent == TRUE){# imputation used all data, so restrict here
  consented = filter(researchers, consent == 'Yes') %>% pull(number)
  for (k in 1:n_impute){
    analysis_ready_imputed[[k]] = filter(analysis_ready_imputed[[k]], floor(number) %in% consented)
  }
}

```

This analysis uses bibliographic data from researchers. 
The follow-up dates were `r format(scholar_date, '%d-%b-%Y')` for _Google Scholar_, `r format(scopus_date, '%d-%b-%Y')` for _Scopus_, `r format(researchgate_date, '%d-%b-%Y')` for _researchgate_, and `r format(altmetric_date, '%d-%b-%Y')` for _Altmetric_. 

###### page break

# Yearly publication counts

First we examine the effect of funding on yearly publication counts. 

```{r, include=FALSE}
file = c('bayes', 'main_publication_counts')
outfile = make_file(file, only_consent = only_consent)
if(outfile$exists == FALSE){
  # model choices:
  pilot = FALSE # run big model
  # loop through imputations
  results = list() # list to store results
  for (imp in 1:n_impute){
    source('99_nimble_publications.R')
    results[[imp]] = results_main
  }
  save(results, pilot, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
results_main = results # rename
```


### Estimates using imputed data

The baseline publication counts were imputed when missing. The plots below show the estimates from 5 imputations. Imputing the missing baseline data had very little effect on the estimates.

```{r}
# combine and plot the results
combined_results = NULL
for (k in 1:n_impute){
  this_table = bind_rows(results_main[[k]]$table) %>%
    mutate(imputation = k) 
  combined_results = bind_rows(combined_results, this_table)
}
# just show first five
isample = 1:5
combined_results = filter(combined_results, imputation %in% isample)
#
ests_plot = ggplot(data = combined_results, aes(x = imputation, y=mean, ymin=lower, ymax=upper))+
  geom_point()+
  geom_errorbar(width=0)+
  xlab('Imputation')+
  ylab('Estimate')+
  coord_flip()+
  theme_bw()+
  facet_wrap(~parameter, scales='free')
ests_plot
```


```{r combine, include=FALSE}
# combine the imputations 
coef = vcov = NULL
for (k in 1:n_impute){
  chains = rbind(results_main[[k]]$chains[[1]],
                 results_main[[k]]$chains[[2]])
  coef[[k]] = colMeans(chains[,1:5]) # ignore tau
  vcov[[k]] = cov(chains[,1:5])
}
# combine the estimates from the imputations
ests = summary(MIcombine(coef, vcov)) %>%
  tibble::rownames_to_column()  %>%
  rename('mean' = 'results',
         'lower' = '(lower',
         'upper' = 'upper)')
```

### Table of estimates (yearly publication data)

The table below uses the combined estimates from imputation.

```{r}
to_table = filter(ests, 
    str_detect(rowname, pattern='beta|gamma')) %>% # do not show intercept
  mutate(term = parameter_rename(rowname),
#  pvalue = format.pval(pvalue, digits=2, eps=0.0001), # not in imputed data
    mean = exp(mean), # rate ratio
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 2), # rounding
         lower = roundz(lower, 2),
         upper = roundz(upper, 2),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```

The table below uses the estimates from a single imputation.

```{r}
to_table = filter(results_main[[1]]$table, 
    str_detect(parameter, pattern='beta|gamma')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001), # not in imputed data
    mean = exp(mean), # rate ratio
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 2), # rounding
         lower = roundz(lower, 2),
         upper = roundz(upper, 2),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```

The table shows estimated rate ratios, 95% credible intervals, and Bayesian posterior p-value.

As expected there was a strong effect of the number of papers a researcher had prior to randomisation on their post-randomisation output. 

There was no clear effect of funding, but the 95% credible interval is wide and includes meaningful increases in output (e.g., 20% increase). Hence we can't rule out that there is not a real and large effect of funding. 

## Time-varying treatment (yearly publication data)

We ran a model with a time-varying treatment effect.

```{r, include=FALSE}
file = c('bayes','model_time_varying')
outfile = make_file(file, only_consent = only_consent)
pilot = FALSE
if(outfile$exists == FALSE){
  # loop through imputations
  results_main = list() # list to store results
  for (imp in 1:n_impute){
    source('99_nimble_publications_time_varying.R')
    results_main[[imp]] = results_time_varying
  }
  results_time_varying = results_main # rename
  save(results_time_varying, pilot, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
```

### Model fit

Comparing the model fit between the time-fixed and time-varying model for publication counts.

```{r, fig.width = 6}
# get previous results
load("bayes/main_publication_counts.RData")
results_main = results # rename
n_impute = 10
#
to_plot = NULL
for (k in 1:n_impute){
  fit_table1 = bind_rows(results_main[[k]]$model_fit) %>%
    mutate(imputation = k)
  fit_table2 = bind_rows(results_time_varying[[k]]$model_fit) %>%
    mutate(imputation = k)
  to_plot = bind_rows(to_plot, fit_table1, fit_table2)
}
waic_plot = ggplot(data = to_plot, aes(x = model, y=WAIC))+
  geom_boxplot()+
  geom_point()+
  xlab('Model')+
  theme_bw()
waic_plot
```

The time-fixed model has the smallest WAIC and has fewer parameters. Hence is the preferred model.

```{r combine_varying, include=FALSE}
# combine the imputations 
coef = vcov = NULL
for (k in 1:n_impute){
  chains = rbind(results_time_varying[[k]]$chains[[1]],
                 results_time_varying[[k]]$chains[[2]])
  coef[[k]] = colMeans(chains[,1:5]) # ignore tau
  vcov[[k]] = cov(chains[,1:5])
}
# combine the estimates from the imputations
ests_varying = summary(MIcombine(coef, vcov)) %>%
  tibble::rownames_to_column()  %>%
  rename('mean' = 'results',
         'lower' = '(lower',
         'upper' = 'upper)')
```

### Table of estimates (yearly publication data - time-varying)

The table below is from the multiple imputations.

```{r}
to_table = filter(ests_varying, 
    str_detect(rowname, pattern='beta|gamma')) %>% # do not show intercept
  mutate(term = parameter_rename(rowname),
#  pvalue = format.pval(pvalue, digits=2, eps=0.0001), # not in imputed data
    mean = exp(mean), # rate ratio
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 2), # rounding
         lower = roundz(lower, 2),
         upper = roundz(upper, 2),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```

The table below is from a single imputation.

```{r}
to_table = filter(results_time_varying[[1]]$table, 
    str_detect(parameter, pattern='beta|gamma')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001), # not in imputed data
    mean = exp(mean), # rate ratio
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 2), # rounding
         lower = roundz(lower, 2),
         upper = roundz(upper, 2),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```


```{r}
time_varying =  filter(results_time_varying[[1]]$table, str_detect(parameter, pattern='^diff')) %>%
  mutate(mean = exp(mean), # rate ratio
      lower = exp(lower),
      upper = exp(upper),
      years_since = str_remove_all(parameter, pattern='[^0-9]'),
      years_since = as.numeric(years_since) - 1) # minus 1 so that first year is zero
# remove later years with extreme uncertainty
#time_varying = filter(time_varying, years_since <=4)

#
splot_main = ggplot(data=time_varying, aes(x=years_since, y=mean, ymin=lower, ymax=upper))+
    geom_hline(lty = 2, yintercept=1)+
    geom_ribbon(alpha = 0.2)+
    geom_point(size=2)+
    geom_line(linewidth = 1.1)+
    xlab('Years since funding')+
    ylab('Rate ratio for publications')+
    theme_bw()+
    theme(panel.grid.minor = element_blank())
splot_main
```


The plot shows no clear benefit to funding on publication counts over time since funding. The 95% credible intervals become wider as the years since funding increases because there are fewer observations and hence more uncertainty (see appendix).

### Table of time-varying estimates (yearly publication data)

```{r}
table = mutate(time_varying,
               lower = roundz(lower, 2),
               upper = roundz(upper, 2),
               ci = paste(lower, ' to ', upper, sep=''),
               pvalue = format.pval(pvalue, digits=2, eps=0.001)) %>%
  dplyr::select(years_since, mean, ci, pvalue) %>%
  rename('years since funding' ='years_since') %>%
  flextable() %>%
  theme_tron_legacy() %>%
  colformat_double(j=2, digits=2) %>%
  autofit()
table
```

### Table of estimates (publications per paper, time-varying)

```{r}
to_table = filter(results_time_varying[[1]]$table, 
    str_detect(parameter, pattern='beta|gamma|delta|lambda|slope.diff')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter, papers=TRUE),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001),
  mean = exp(mean), # rate ratio
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 2), # rounding
         lower = roundz(lower, 2),
         upper = roundz(upper, 2),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```

###### page break

# Scopus only

Here we examine the effect of funding on yearly publication counts using the Scopus database only. 

```{r, include=FALSE}
file = c('bayes', 'main_publication_scopus_only')
outfile = make_file(file, only_consent = only_consent)
if(outfile$exists == FALSE){
  # model choices:
  pilot = FALSE # run big model
  # loop through imputations
  results = list() # list to store results
  for (imp in 1:n_impute){
    source('99_nimble_publications_scopus_only.R')
    results[[imp]] = results_scopus_only
  }
  save(results, pilot, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
results_scopus_only = results # rename
```

### Table of estimates (yearly publication data - Scopus only)

The table below uses the estimates from a single imputation.

```{r}
to_table = filter(results_scopus_only[[1]]$table, 
    str_detect(parameter, pattern='beta|gamma')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001), # not in imputed data
    mean = exp(mean), # rate ratio
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 2), # rounding
         lower = roundz(lower, 2),
         upper = roundz(upper, 2),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```




###### page break

# Citations

```{r, include=FALSE}
# Bayes model does not converge, had to use alternative model
file = c('bayes', 'main_citation_counts_non_bayes')
outfile = make_file(file, only_consent = only_consent)
if(outfile$exists == FALSE){
  # model choices:
  source('99_nimble_citations_alternative.R')
  save(results_citations, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
```

### Table of estimates (citation data)

```{r table_citations}
to_table = filter(results_citations$table, 
    str_detect(parameter, pattern='beta|gamma')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter, papers=FALSE),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001),
    mean = exp(mean), # rate ratio
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 2), # rounding
         lower = roundz(lower, 2),
         upper = roundz(upper, 2),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```

###### page break

# Time-varying citations

```{r, include=FALSE}
# bayes version not converging
file = c('bayes', 'main_citation_time_varying_non_bayes')
outfile = make_file(file, only_consent = only_consent)
if(outfile$exists == FALSE){
  source('99_nimble_citations_time_varying_alternative.R')
  save(results_citations_time_varying, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
```

### Table of estimates (time-varying citation data)

```{r}
to_table = filter(results_citations_time_varying$table, 
    str_detect(parameter, pattern='beta|gamma|years_since|interaction')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter, papers=FALSE),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001),
    mean = exp(mean), # rate ratio
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 2), # rounding
         lower = roundz(lower, 2),
         upper = roundz(upper, 2),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```

```{r}
bayes_version = function(){
  time_varying =  filter(results_citations_time_varying$table, str_detect(parameter, pattern='^diff')) %>%
    mutate(mean = exp(mean), # percent change
           lower = exp(lower),
           upper = exp(upper),
           years_since = str_remove_all(parameter, pattern='[^0-9]'),
           years_since = as.numeric(years_since),
           years_since = years_since-1) # minus 1 so that first year is zero
  splot_main = ggplot(data=time_varying, aes(x=years_since, y=mean, ymin=lower, ymax=upper))+
    geom_hline(lty = 2, yintercept=1)+
    geom_ribbon(alpha = 0.2)+
    geom_point(size=2)+
    geom_line(size = 1.1)+
    xlab('Years since funding')+
    ylab('Rate ratio for citations')+
    theme_bw()+
    theme(panel.grid.minor = element_blank())
}
# non-Bayes version
time_varying = results_citations_time_varying$predict
splot_main = ggplot(data=time_varying, aes(x=years_since, y=fitted, col=factor(funded)))+
    scale_color_manual(NULL, values=c('dodgerblue','darkseagreen'))+ # matching colours used in other plots
    geom_point(size=2)+
    geom_line(size = 1.1)+
    xlab('Years since randomisation')+
    ylab('Predicted citations')+
    theme_bw()+
    theme(legend.position = c(0.18,0.8),
          panel.grid.minor = element_blank())
#
splot_main
# export to plot
jpeg('figures/citations_time_varying.jpg', width=5, height=4, units='in', res=500, quality=100)
print(splot_main)
invisible(dev.off())
```

###### page break

# Citation counts per paper

The following results examine citation counts per paper. The outcome was created by dividing the cumulative number of citations over years by the cumulative number of papers. These data use a single database and so are not fitted as a multivariate model.

```{r, include=FALSE}
file = c('bayes', 'main_citation_per_paper')
outfile = make_file(file, only_consent = only_consent)
if(outfile$exists == FALSE){
  # model choices:
  pilot = FALSE # run big model
  source('99_nimble_citations_per_paper.R')
  save(results_citations_per_paper, pilot, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
```

### Table of estimates (citations per paper)

```{r}
to_table = filter(results_citations_per_paper$table, 
    str_detect(rowname, pattern='beta|gamma')) %>% # do not show intercept
  mutate(term = parameter_rename(rowname, papers=FALSE),
  pvalue = format.pval(Bayes_prob, digits=2, eps=0.0001),
  mean = roundz(mean, 1), # rounding
         lower = roundz(lower, 1),
         upper = roundz(upper, 1),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```

The results are on an absolute scale, which is citations per paper. There is no effect of funding on the number of citations per paper. 

###### page break

# Time-varying citations per paper

```{r, include=FALSE}
file = c('bayes', 'main_citation_per_paper_time_varying')
outfile = make_file(file, only_consent = only_consent)
if(outfile$exists == FALSE){
  # model choices:
  pilot = FALSE # run big model
  source('99_nimble_citations_per_paper_time_varying.R')
  save(results_citations_per_paper_time_varying, pilot, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
```

```{r}
time_varying =  filter(results_citations_per_paper_time_varying$table, str_detect(parameter, pattern='^diff')) %>%
  mutate(years_since = str_remove_all(parameter, pattern='[^0-9]'),
      years_since = as.numeric(years_since),
      years_since = years_since - 1) #  /
#
splot_main = ggplot(data=time_varying, aes(x=years_since, y=mean, ymin=lower, ymax=upper))+
    geom_hline(lty = 2, yintercept=0)+
    geom_ribbon(alpha = 0.2)+
    geom_point(size=2)+
    geom_line(size = 1.1)+
    xlab('Years since funding')+
    ylab('Percent change in citations per paper')+
    theme_bw()+
    theme(panel.grid.minor = element_blank())
splot_main
```

### Table of estimates (citations per paper, time-varying)

```{r}
to_table = filter(results_citations_per_paper_time_varying$table, 
    str_detect(parameter, pattern='beta|gamma|delta|lambda|slope.diff')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter, papers=FALSE),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001),
  mean = roundz(mean, 1), # rounding
         lower = roundz(lower, 1),
         upper = roundz(upper, 1),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```


###### page break

# Altmetric score

```{r, include=FALSE}
file = c('bayes', 'altmetric')
outfile = make_file(file, only_consent = only_consent)
if(outfile$exists == FALSE){
  # model choices:
  pilot = FALSE # run big model
  source('99_nimble_altmetric.R')
  save(results_altmetric, pilot, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
```

### Table of estimates (altmetric)

```{r}
to_table = filter(results_altmetric$table, 
    str_detect(parameter, pattern='beta|gamma')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter, papers=FALSE),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001),
    mean = roundz(mean, 1), # rounding
         lower = roundz(lower, 1),
         upper = roundz(upper, 1),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```

The estimate are on an absolute scale.

###### page break

# Altmetric score time-varying

```{r, include=FALSE}
file = c('bayes', 'altmetric_time_varying')
outfile = make_file(file, only_consent = only_consent)
if(outfile$exists == FALSE){
  # model choices:
  pilot = FALSE # run big model
  source('99_nimble_altmetric_time_varying.R')
  save(results_altmetric_time_varying, pilot, file = outfile$file)
}
if(outfile$exists == TRUE){
  load(outfile$file)
}
```

### Table of estimates (altmetric, time-varying)

```{r}
to_table = filter(results_altmetric_time_varying$table, 
    str_detect(parameter, pattern='beta|gamma|lambda|delta|slope.diff')) %>% # do not show intercept
  mutate(term = parameter_rename(parameter, papers=FALSE),
  pvalue = format.pval(pvalue, digits=2, eps=0.0001),
  mean = roundz(mean, 1), # rounding
         lower = roundz(lower, 1),
         upper = roundz(upper, 1),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(term, mean, ci, pvalue)
ftab = flextable(to_table)%>%
  autofit() %>%
  theme_box()
ftab
```


###### page break

# Employment

```{r}
# assume still employed if the entered the randomisation
# model probability of being unemployed (outcome = zero)
smodel = coxph(Surv(time, outcome==0) ~ I(funded=='Funded') + cluster(number), data = analysis_ready_employment)
ests = tidy(smodel, conf.int=TRUE, exponentiate = TRUE) %>%
  select(term, estimate, conf.low, conf.high)
ests$term = 'Funded'
ftab = flextable(ests) %>%
  theme_box() %>%
  autofit() %>%
  colformat_double(j=2:4, digits=2)
ftab
```

We use a survival model to examine employment. We only collected employment data at the end of the follow-up, meaning we did not have repeated data for researchers who submitted multiple applications. We assumed they were still employed as a researcher if they re-applied and were entered into the Lottery.

The table above shows the hazard ratio and 95% confidence interval using the outcome of not employed. A hazard ratio above 1 indicates a higher probability of no longer being employed.

The plot below shows the Kaplan-Meier curves for the two groups.

```{r, fig.height=7}
sfit = survfit(Surv(time, outcome==0) ~ funded + cluster(number), data=analysis_ready_employment)
ggsurvplot(sfit, 
           conf.int = TRUE,
           palette = c("skyblue", "indianred2"),
           legend.labs = c("Funded", "Not funded"),
           xlab = "Time since randomisation, years",
           risk.table = TRUE,
           data = analysis_ready_employment)
```

###### page break

# Summary tables

#### Main effect of funding

The table below shows the main effect of funding for the rate ratios.

```{r relative}
t1 = filter(results_main[[1]]$table,  # use first imputation, barely matters
    str_detect(parameter, pattern='gamma'))
t2 = filter(results_time_varying[[1]]$table, 
    str_detect(parameter, pattern='gamma'))
t5 = filter(results_citations$table, 
    str_detect(parameter, pattern='gamma'))
t6 = filter(results_citations_time_varying$table, 
    str_detect(parameter, pattern='gamma'))
summary_table = bind_rows(t1, t2, t5, t6, .id='id') %>%
  mutate(
    outcome = case_when(
      id == 1 ~ 'Publications',
      id == 2 ~ 'Publications',
      id == 3 ~ 'Citations',
      id == 4 ~ 'Citations'),
  time_varying = case_when(
      id == 1 ~ 'No',
      id == 2 ~ 'Yes',
      id == 3 ~ 'No',
      id == 4 ~ 'Yes')) %>%
  mutate(pvalue = format.pval(pvalue, digits = 2, eps=0.0001),
    mean = exp(mean), # RR
           lower = exp(lower),
           upper = exp(upper),
  mean = roundz(mean, 1), # rounding
         lower = roundz(lower, 1),
         upper = roundz(upper, 1),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(outcome, time_varying, mean, ci, pvalue)
ftab = flextable(summary_table) %>%
  theme_box() %>%
  autofit() %>%
  merge_v(j=1)
ftab
```

The table below shows the main effect of funding for the absolute estimates.


```{r abs}
t7 = rename(results_citations_per_paper$table, 'parameter' = 'rowname') %>%
  filter(str_detect(parameter, pattern='gamma'))
t8 = filter(results_citations_per_paper_time_varying$table, 
    str_detect(parameter, pattern='gamma'))
t9 = filter(results_altmetric$table, 
    str_detect(parameter, pattern='gamma'))
t10 = filter(results_altmetric_time_varying $table, 
    str_detect(parameter, pattern='gamma'))
summary_table = bind_rows(t7, t8, t9, t10, .id='id') %>%
  mutate(
    outcome = case_when(
      id == 1 ~ 'Citations per paper',
      id == 2 ~ 'Citations per paper',
      id == 3 ~ 'Altmetric',
      id == 4 ~ 'Altmetric'
  ),
  time_varying = case_when(
      id == 1 ~ 'No',
      id == 2 ~ 'Yes',
      id == 3 ~ 'No',
      id == 4 ~ 'Yes'
  )) %>%
  mutate(pvalue = format.pval(pvalue, digits = 2, eps=0.0001),
    mean = roundz(mean, 1), # rounding
         lower = roundz(lower, 1),
         upper = roundz(upper, 1),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(outcome, time_varying, mean, ci, pvalue)
ftab = flextable(summary_table) %>%
  theme_box() %>%
  autofit() %>%
  merge_v(j=1)
ftab
```


#### Change in the effect of funding over time

The table below shows the main effect of funding for the rate ratios.

```{r}
t2 = filter(results_time_varying[[1]]$table, 
    str_detect(parameter, pattern='slope.diff'))
t6 = filter(results_citations_time_varying$table, 
    str_detect(parameter, pattern='slope.diff'))
summary_table = bind_rows(t2, t6, .id='id') %>%
  mutate(
    outcome = case_when(
      id == 1 ~ 'Publications',
      id == 2 ~ 'Citations'
  )) %>%
  mutate(pvalue = format.pval(pvalue, digits = 2, eps=0.0001),
    mean = 100*(exp(mean)- 1), # percent change
           lower = 100*(exp(lower)- 1),
           upper = 100*(exp(upper)- 1),
  mean = roundz(mean, 1), # rounding
         lower = roundz(lower, 1),
         upper = roundz(upper, 1),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(outcome, mean, ci, pvalue)
ftab = flextable(summary_table) %>%
  theme_box() %>%
  autofit() %>%
  merge_v(j=1)
ftab
```

The table below shows the main effect of funding over time for the absolute estimates.

```{r}
t2 = filter(results_time_varying[[1]]$table, 
    str_detect(parameter, pattern='slope.diff'))
t6 = filter(results_citations_time_varying$table, 
    str_detect(parameter, pattern='slope.diff'))
summary_table = bind_rows(t8, t10, .id='id') %>%
  mutate(
    outcome = case_when(
      id == 1 ~ 'Citations per paper',
      id == 2 ~ 'Altmetric'
  )) %>%
  mutate(pvalue = format.pval(pvalue, digits = 2, eps=0.0001),
  mean = roundz(mean, 1), # rounding
         lower = roundz(lower, 1),
         upper = roundz(upper, 1),
         ci = paste(lower , ' to ' , upper, sep='')) %>%
  dplyr::select(outcome, mean, ci, pvalue)
ftab = flextable(summary_table) %>%
  theme_box() %>%
  autofit() %>%
  merge_v(j=1)
ftab
```


###### page break

# Appendix

Here we show some additional results for: 1) variance-covariance matrix and correlation matrix for the three databases, 2) the model residuals.

### Variance-covariance matrix (yearly publication data)

```{r}
cmat = mutate(results_main[[1]]$covmat, 
              row = case_when(
                row==1 ~ 'Scholar',
                row==2 ~ 'Scopus',
                row==3 ~ 'Researchgate'
              ))
names(cmat) = c('row','Scholar','Scopus','Researchgate')
ftab  = flextable(cmat) %>%
  colformat_double(digits=2) %>%
  autofit() %>%
  theme_box()
ftab
```

### Correlation matrix (yearly publication data)

```{r}
cormat = cov2cor(as.matrix(results_main[[1]]$covmat[,-1])) %>%
  data.frame() %>%
  mutate(row = 1:3) %>%
  select(row, everything())
cmat = mutate(cormat, 
              row = case_when(
                row==1 ~ 'Scholar',
                row==2 ~ 'Scopus',
                row==3 ~ 'Researchgate'
              ))
names(cmat) = c('row','Scholar','Scopus','Researchgate')
ftab  = flextable(cmat) %>%
  colformat_double(digits=2) %>%
  autofit() %>%
  theme_box()
ftab
```

### Residual checks (yearly publication data)

```{r, fig.width=8}
res = results_main[[1]]$residuals
hplot = ggplot(data=res, aes(x=residual))+
  geom_histogram(col='grey44', fill='skyblue')+
  g.theme+
  xlab('Residual')+
  ylab('Count')+
  facet_wrap(~database, scales='free')
hplot
```

The histograms are centered on zero and roughly symmetric. 

The relatively large negative residual in the Scopus database is for a relatively experienced researcher with zero outputs in 2022.

### Residual checks (yearly publication data, time-varying effect)

```{r, fig.width=8}
res = results_time_varying[[1]]$residuals
hplot = ggplot(data=res, aes(x=residual))+
  geom_histogram(col='grey44', fill='skyblue')+
  g.theme+
  xlab('Residual')+
  ylab('Count')+
  facet_wrap(~database, scales='free')
hplot
```

The histograms are centered on zero and roughly symmetric. 


### Residual checks (citations)

```{r, fig.width=8}
res = results_citations$residuals
hplot = ggplot(data=res, aes(x=residual))+
  geom_histogram(col='grey44', fill='skyblue')+
  g.theme+
  xlab('Residual')+
  ylab('Count')
hplot
```

The three relatively large positive citations are for the most recent three years of the same researcher. 

### Residual checks (time-varying citations)

```{r, fig.width=8}
res = results_citations_time_varying$residuals
hplot = ggplot(data=res, aes(x=residual))+
  geom_histogram(col='grey44', fill='skyblue')+
  g.theme+
  xlab('Residual')+
  ylab('Count')
hplot
```


### Residual checks (citations per paper)

```{r, fig.width=8}
res = results_citations_per_paper$residuals
hplot = ggplot(data=res, aes(x=residual))+
  geom_histogram(col='grey44', fill='skyblue')+
  g.theme+
  xlab('Residual')+
  ylab('Count')
hplot
```

### Researcher numbers over time

The plot below shows the number of researchers by group and years since funding. The numbers drop off with longer follow-up.

```{r}
tab = group_by(analysis_ready, funded, years_since) %>%
  tally() %>%
  mutate(years_since = years_since - 1)
ftab = rename(tab, 'number of\nresearchers' = 'n') %>%
  flextable() %>%
  merge_v(j=1) %>%
  theme_box() %>%
  autofit()
#ftab
tplot = ggplot(data=tab, aes(x=years_since, y=n, col=factor(funded)))+
  geom_line(size=1.05)+
  geom_point(size=2.5)+
  scale_color_manual(NULL, values=c('dark orange','navy'))+
  ylab('Number of researchers')+
  xlab('Years since randomisation')+
  g.theme+
  theme(panel.grid.minor=element_blank(),
        legend.position = c(0.85, 0.85))
tplot
jpeg('figures/researchers_over_time.jpg', width=5, height=4, units='in', quality = 100, res=400)
print(tplot)
invisible(dev.off())
```


```{r}
years_follow = group_by(analysis_ready, number) %>%
  summarise(start = min(year)) %>%
  mutate(years = 2022.5 - start -0.5) %>% # take of half for funding announcement
  summarise(total = sum(years))
```

The total years of follow-up was `r years_follow$total`.

# Convergence checks

Checking the convergence of the MCMC.

###### page break

### Densities (publication counts)

```{r, fig.height=8}
library(ggmcmc) # for chain diagnostics
chains = results_main[[1]]$chains
c1 = mcmc(data= chains[[1]], start = 1, end = dim(chains[[1]])[1])
c2 = mcmc(data= chains[[2]], start = 1, end = dim(chains[[1]])[1])
chains = as.mcmc.list(list(c1,c2))
res = ggs(S = chains, burnin=FALSE) # make into object for ggmcmc
ggs_density(res)
```

###### page break

### Traces (publication counts)

```{r, fig.height=8}
ggs_traceplot(res)
```



###### page break

### Densities (citations per paper)

```{r, fig.height=8}
chains = results_citations_per_paper$chains
c1 = mcmc(data= chains[[1]], start = 1, end = dim(chains[[1]])[1])
c2 = mcmc(data= chains[[2]], start = 1, end = dim(chains[[1]])[1])
chains = as.mcmc.list(list(c1,c2))
res = ggs(S = chains, burnin=FALSE) # make into object for ggmcmc
ggs_density(res)
```

###### page break

### Traces (citations per paper)

```{r, fig.height=8}
ggs_traceplot(res)
```


###### page break

### Densities (altmetric)

```{r, fig.height=8}
chains = results_altmetric$chains
c1 = mcmc(data= chains[[1]], start = 1, end = dim(chains[[1]])[1])
c2 = mcmc(data= chains[[2]], start = 1, end = dim(chains[[1]])[1])
chains = as.mcmc.list(list(c1,c2))
res = ggs(S = chains, burnin=FALSE) # make into object for ggmcmc
ggs_density(res)
```

###### page break

### Traces (altmetric)

```{r, fig.height=8}
ggs_traceplot(res)
```

